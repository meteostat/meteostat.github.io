(window.webpackJsonp=window.webpackJsonp||[]).push([[34],{385:function(t,a,s){"use strict";s.r(a);var e=s(42),n=Object(e.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"daily-data"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#daily-data"}},[t._v("#")]),t._v(" Daily Data")]),t._v(" "),s("p",[t._v("Aggregated daily data is very useful when analyzing weather and climate over a longer period of time. The data provided through the "),s("code",[t._v("Daily")]),t._v(" class contains only aggregated observations. Model data is not included in those statistics which makes the data very accurate, but causes some gaps in the time series.")]),t._v(" "),s("h2",{attrs:{id:"data-access"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#data-access"}},[t._v("#")]),t._v(" Data Access")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("Daily")]),t._v(" class takes a mandatory "),s("code",[t._v("stations")]),t._v(" parameter which can either be supplied with a fetched query to the "),s("code",[t._v("Stations")]),t._v(" class or a list of Meteostat weather station identifiers. Furthermore, you can pass a "),s("code",[t._v("start")]),t._v(" and "),s("code",[t._v("end")]),t._v(" datetime to limit your query to a certain time range. Let's have a look at this example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Import requirements")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" meteostat "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Stations"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Daily\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get closest weather station to Vancouver, BC")]),t._v("\nstations "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Stations"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("lat "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("49.2497")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lon "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("123.1193")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nstation "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" stations"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fetch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get daily data for 2018 at the selected weather station")]),t._v("\ndata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Daily"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("station"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" start "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2018")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" end "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2018")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("31")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ndata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fetch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Plot line chart including average, minimum and maximum temperature")]),t._v("\ndata"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("x "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'time'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tavg'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tmin'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tmax'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kind "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'line'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("The "),s("code",[t._v("fetch()")]),t._v(" method returns a Pandas DataFrame with multiple meteorological columns.")]),t._v(" "),s("h2",{attrs:{id:"response-parameters"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#response-parameters"}},[t._v("#")]),t._v(" Response Parameters")]),t._v(" "),s("p",[t._v("The DataFrame provides the following columns:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("station")]),t._v(": The Meteostat ID of the weather station")]),t._v(" "),s("li",[s("code",[t._v("time")]),t._v(": The date")]),t._v(" "),s("li",[s("code",[t._v("tavg")]),t._v(": The average air temperature in "),s("em",[t._v("째C")])]),t._v(" "),s("li",[s("code",[t._v("tmin")]),t._v(": The minimum air temperature in "),s("em",[t._v("째C")])]),t._v(" "),s("li",[s("code",[t._v("tmax")]),t._v(": The maximum air temperature in "),s("em",[t._v("째C")])]),t._v(" "),s("li",[s("code",[t._v("prcp")]),t._v(": The daily precipitation total in "),s("em",[t._v("mm")])]),t._v(" "),s("li",[s("code",[t._v("snow")]),t._v(": The snow depth in "),s("em",[t._v("mm")])]),t._v(" "),s("li",[s("code",[t._v("wdir")]),t._v(": The average wind direction in degrees ("),s("em",[t._v("째")]),t._v(")")]),t._v(" "),s("li",[s("code",[t._v("wspd")]),t._v(": The average wind speed in "),s("em",[t._v("km/h")])]),t._v(" "),s("li",[s("code",[t._v("wpgt")]),t._v(": The peak wind gust in "),s("em",[t._v("km/h")])]),t._v(" "),s("li",[s("code",[t._v("pres")]),t._v(": The average sea-level air pressure in "),s("em",[t._v("hPa")])]),t._v(" "),s("li",[s("code",[t._v("tsun")]),t._v(": The daily sunshine total in minutes ("),s("em",[t._v("m")]),t._v(")")])]),t._v(" "),s("h2",{attrs:{id:"normalization"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#normalization"}},[t._v("#")]),t._v(" Normalization")]),t._v(" "),s("p",[t._v("Meteostat essentially skips gaps in its time series. Therefore, the raw response does not necessarily contain one row per day. You can make sure gaps are filled with "),s("code",[t._v("nan")]),t._v(" values by applying the "),s("code",[t._v("normalize()")]),t._v(" method. Our example from above could easily be normalized by making a small change:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get daily data for 2018 at the selected weather station")]),t._v("\ndata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Daily"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("station"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" start "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2018")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" end "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2018")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("31")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Normalize and fetch")]),t._v("\ndata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normalize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fetch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"interpolation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#interpolation"}},[t._v("#")]),t._v(" Interpolation")]),t._v(" "),s("p",[t._v("Normalizing your data paves the way for interpolation. The "),s("code",[t._v("interpolate()")]),t._v(" method closes gaps in your time series using linear regression. It takes a "),s("code",[t._v("limit")]),t._v(" parameter which specifies the maximum number of consecutive "),s("code",[t._v("nan")]),t._v(" values. The default value of "),s("code",[t._v("3")]),t._v(" means that up to three consecutive missing days are interpolated. Again, we can simply adapt our existing example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get daily data for 2018 at the selected weather station")]),t._v("\ndata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Daily"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("station"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" start "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2018")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" end "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2018")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("31")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Normalize, interpolate and fetch")]),t._v("\ndata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normalize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("interpolate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("limit "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fetch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h2",{attrs:{id:"aggregation"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#aggregation"}},[t._v("#")]),t._v(" Aggregation")]),t._v(" "),s("p",[t._v("Aggregation is another important tool in data science. Meteostat provides an "),s("code",[t._v("aggregate()")]),t._v(" method for time-wise and spatial aggregation. It takes a "),s("code",[t._v("freq")]),t._v(" parameter which specifies the frequency of our aggregation. Optionally, you can overwrite the default aggregation functions by passing a dictionary to the "),s("code",[t._v("functions")]),t._v(" parameter. If you want to apply aggregation across all weather stations in your result, just set the "),s("code",[t._v("spatial")]),t._v(" parameter to "),s("code",[t._v("True")]),t._v(".")]),t._v(" "),s("p",[t._v("Let's dig into the "),s("a",{attrs:{href:"https://github.com/meteostat/meteostat-python/wiki/Weather-Stations#sample",target:"_blank",rel:"noopener noreferrer"}},[t._v("sampled"),s("OutboundLink")],1),t._v(" US average temperatures for the past 40 years as an example:")]),t._v(" "),s("div",{staticClass:"language-python extra-class"},[s("pre",{pre:!0,attrs:{class:"language-python"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Import requirements")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" meteostat "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Stations"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Daily\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datetime "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" datetime\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" matplotlib"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pyplot "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" plt\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get 50 random weather stations in the US which generally provide daily data")]),t._v("\nstations "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Stations"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("country "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'US'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" daily "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2005")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sample"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("50")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fetch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Get daily data for all weather stations")]),t._v("\ndata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Daily"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("stations"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" start "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1980")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" end "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" datetime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2019")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("12")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("31")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Normalize and aggregate the statistics annually across all weather stations")]),t._v("\ndata "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("normalize"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("aggregate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("freq "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1Y'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" spatial "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("True")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fetch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Plot a chart of the average temperature")]),t._v("\ndata"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("plot"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("y "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tavg'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" kind "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'line'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" title "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Average US Annual Temperature from 1980 to 2019'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nplt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("show"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"default-aggregation-functions"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#default-aggregation-functions"}},[t._v("#")]),t._v(" Default Aggregation Functions")]),t._v(" "),s("p",[t._v("By default, Meteostat uses the following aggregation functions:")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("time")]),t._v(" => "),s("code",[t._v("first")])]),t._v(" "),s("li",[s("code",[t._v("tavg")]),t._v(" => "),s("code",[t._v("mean")])]),t._v(" "),s("li",[s("code",[t._v("tmin")]),t._v(" => "),s("code",[t._v("min")])]),t._v(" "),s("li",[s("code",[t._v("tmax")]),t._v(" => "),s("code",[t._v("max")])]),t._v(" "),s("li",[s("code",[t._v("prcp")]),t._v(" => "),s("code",[t._v("sum")])]),t._v(" "),s("li",[s("code",[t._v("snow")]),t._v(" => "),s("code",[t._v("mean")])]),t._v(" "),s("li",[s("code",[t._v("wdir")]),t._v(" => "),s("code",[t._v("mean")])]),t._v(" "),s("li",[s("code",[t._v("wspd")]),t._v(" => "),s("code",[t._v("mean")])]),t._v(" "),s("li",[s("code",[t._v("wpgt")]),t._v(" => "),s("code",[t._v("max")])]),t._v(" "),s("li",[s("code",[t._v("pres")]),t._v(" => "),s("code",[t._v("mean")])]),t._v(" "),s("li",[s("code",[t._v("tsun")]),t._v(" => "),s("code",[t._v("sum")])])]),t._v(" "),s("p",[t._v("You can overwrite the defaults by passing a dictionary to the "),s("code",[t._v("functions")]),t._v(" parameter.")]),t._v(" "),s("h2",{attrs:{id:"data-coverage"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#data-coverage"}},[t._v("#")]),t._v(" Data Coverage")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("coverage()")]),t._v(" method returns a float value which describes the completeness of a DataFrame or series. A value of "),s("code",[t._v("1")]),t._v(" (= 100%) means that the dataset is complete. The method takes an optional "),s("code",[t._v("parameter")]),t._v(" attribute. If present, the method returns the coverage for that particular parameter instead of the whole DataFrame.")]),t._v(" "),s("h2",{attrs:{id:"fetch"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#fetch"}},[t._v("#")]),t._v(" Fetch")]),t._v(" "),s("p",[t._v("The "),s("code",[t._v("fetch()")]),t._v(" method returns a Pandas DataFrame.")])])}),[],!1,null,null,null);a.default=n.exports}}]);